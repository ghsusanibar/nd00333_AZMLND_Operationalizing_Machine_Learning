{"8343fe27-af60-4491-8dad-49e57370ae41_20":{"weighted_accuracy":[0.7201543160930906],"f1_score_weighted":[0.7691800389100131],"average_precision_score_macro":[0.7022257962545408],"AUC_macro":[0.8460819295509427],"average_precision_score_micro":[0.8227787307857419],"f1_score_macro":[0.5922291048892389],"log_loss":[0.5197988442498553],"f1_score_micro":[0.7197875569044007],"precision_score_weighted":[0.8733052534501532],"balanced_accuracy":[0.7182638692154194],"norm_macro_recall":[0.4365277384308386],"AUC_weighted":[0.8460819295509427],"precision_score_macro":[0.59843799459162],"precision_score_micro":[0.7197875569044007],"accuracy":[0.7197875569044007],"AUC_micro":[0.8345394986195573],"recall_score_weighted":[0.7197875569044007],"recall_score_macro":[0.7182638692154194],"matthews_correlation":[0.2931498885013123],"recall_score_micro":[0.7197875569044007],"average_precision_score_weighted":[0.9147690101703475]},"8343fe27-af60-4491-8dad-49e57370ae41_21":{"average_precision_score_weighted":[0.9114615581730081],"precision_score_macro":[0.5987256125817899],"accuracy":[0.7219423368740516],"balanced_accuracy":[0.7177546239630755],"weighted_accuracy":[0.7229925640191517],"average_precision_score_micro":[0.80097051761276],"recall_score_micro":[0.7219423368740516],"recall_score_weighted":[0.7219423368740516],"precision_score_micro":[0.7219423368740516],"matthews_correlation":[0.2932242786167164],"AUC_micro":[0.8309159461270468],"f1_score_macro":[0.5933961369246094],"log_loss":[0.5273142240549925],"AUC_macro":[0.8357922242410798],"average_precision_score_macro":[0.6988551443418319],"f1_score_micro":[0.7219423368740516],"f1_score_weighted":[0.7707842378534255],"recall_score_macro":[0.7177546239630755],"precision_score_weighted":[0.8730117158009211],"norm_macro_recall":[0.435509247926151],"AUC_weighted":[0.8357922242410798]},"8343fe27-af60-4491-8dad-49e57370ae41_3":{"precision_score_weighted":[0.9158154083446075],"log_loss":[0.34509565080441157],"precision_score_macro":[0.7137308271246344],"norm_macro_recall":[0.6902888610427428],"accuracy":[0.8680121396054629],"average_precision_score_weighted":[0.9432921554736383],"balanced_accuracy":[0.8451444305213714],"recall_score_macro":[0.8451444305213714],"matthews_correlation":[0.5428422999094209],"recall_score_micro":[0.8680121396054629],"AUC_micro":[0.9292901093992139],"recall_score_weighted":[0.8680121396054629],"f1_score_macro":[0.751556915199911],"precision_score_micro":[0.8680121396054629],"average_precision_score_micro":[0.9106855134738885],"f1_score_weighted":[0.8835042989011892],"average_precision_score_macro":[0.7805811561991486],"weighted_accuracy":[0.8737116582518671],"f1_score_micro":[0.8680121396054629],"AUC_macro":[0.9276152660706598],"AUC_weighted":[0.9276152660706598]},"8343fe27-af60-4491-8dad-49e57370ae41_15":{"recall_score_weighted":[0.89845220030349],"balanced_accuracy":[0.5762505676533399],"recall_score_micro":[0.89845220030349],"AUC_micro":[0.974156378013314],"precision_score_macro":[0.815556129717914],"log_loss":[0.2068446639289295],"f1_score_macro":[0.6019639998368504],"average_precision_score_macro":[0.7903215800095975],"precision_score_weighted":[0.8837778036448014],"weighted_accuracy":[0.9784173715084927],"matthews_correlation":[0.30454458623997127],"f1_score_micro":[0.89845220030349],"norm_macro_recall":[0.15250113530667964],"average_precision_score_micro":[0.9752429209400912],"AUC_macro":[0.9300074946604887],"AUC_weighted":[0.9300074946604887],"f1_score_weighted":[0.8685794833473995],"precision_score_micro":[0.89845220030349],"recall_score_macro":[0.5762505676533399],"average_precision_score_weighted":[0.9457573175517687],"accuracy":[0.89845220030349]},"8343fe27-af60-4491-8dad-49e57370ae41_18":{"f1_score_macro":[0.721783145288595],"weighted_accuracy":[0.8463905090589682],"AUC_macro":[0.9079944239462779],"precision_score_weighted":[0.9092667033130659],"balanced_accuracy":[0.8303307901488347],"average_precision_score_macro":[0.763311088441986],"AUC_weighted":[0.9079944239462779],"log_loss":[0.437124643479876],"recall_score_macro":[0.8303307901488347],"precision_score_micro":[0.8432473444613049],"precision_score_macro":[0.6880176635686519],"recall_score_weighted":[0.8432473444613049],"norm_macro_recall":[0.6606615802976694],"accuracy":[0.8432473444613049],"f1_score_micro":[0.843247344461305],"f1_score_weighted":[0.8643426965216421],"average_precision_score_weighted":[0.9367301712876046],"average_precision_score_micro":[0.8594436876217623],"AUC_micro":[0.890040710968244],"matthews_correlation":[0.4982172898706084],"recall_score_micro":[0.8432473444613049]},"8343fe27-af60-4491-8dad-49e57370ae41_16":{"recall_score_micro":[0.7230652503793625],"f1_score_micro":[0.7230652503793626],"recall_score_macro":[0.7424108042381407],"AUC_macro":[0.8660864741394299],"AUC_micro":[0.8548601942060555],"average_precision_score_micro":[0.8624010380769755],"f1_score_weighted":[0.7722898813582592],"log_loss":[0.5057337595680773],"average_precision_score_weighted":[0.922953372994551],"AUC_weighted":[0.8660864741394301],"precision_score_macro":[0.6078815312857024],"accuracy":[0.7230652503793625],"balanced_accuracy":[0.7424108042381407],"weighted_accuracy":[0.7182588233534704],"norm_macro_recall":[0.48482160847628125],"recall_score_weighted":[0.7230652503793625],"precision_score_weighted":[0.8817376990137626],"f1_score_macro":[0.602043858764634],"matthews_correlation":[0.32341353346978113],"precision_score_micro":[0.7230652503793625],"average_precision_score_macro":[0.7216527311860352]},"8343fe27-af60-4491-8dad-49e57370ae41_27":{"AUC_macro":[0.6625223366601961],"recall_score_weighted":[0.7679514415781487],"f1_score_weighted":[0.7573553622712705],"precision_score_micro":[0.7679514415781487],"balanced_accuracy":[0.6363282649808891],"f1_score_macro":[0.5620010916558306],"norm_macro_recall":[0.27265652996177825],"accuracy":[0.7679514415781487],"log_loss":[6.979154616107834],"precision_score_weighted":[0.8943017940429995],"weighted_accuracy":[0.7996786857195209],"AUC_weighted":[0.6625223366601961],"recall_score_micro":[0.7679514415781487],"average_precision_score_weighted":[0.8493220210814798],"AUC_micro":[0.7693959256794564],"recall_score_macro":[0.6363282649808891],"matthews_correlation":[0.31531395982113164],"f1_score_micro":[0.7679514415781487],"precision_score_macro":[0.7412309416232498],"average_precision_score_micro":[0.7702552307881849],"average_precision_score_macro":[0.5908646787968764]},"8343fe27-af60-4491-8dad-49e57370ae41_25":{"AUC_macro":[0.9267816862195225],"recall_score_micro":[0.8918968133535661],"balanced_accuracy":[0.5264781433892184],"recall_score_weighted":[0.8918968133535661],"average_precision_score_macro":[0.779987621504967],"recall_score_macro":[0.5264781433892184],"precision_score_weighted":[0.8754864640927087],"precision_score_macro":[0.8140704862444696],"weighted_accuracy":[0.9826673809929056],"log_loss":[0.22897286907902573],"norm_macro_recall":[0.05295628677843682],"AUC_micro":[0.9729252903074277],"accuracy":[0.8918968133535661],"f1_score_micro":[0.8918968133535661],"average_precision_score_weighted":[0.9431776481267748],"f1_score_weighted":[0.8484392981476961],"precision_score_micro":[0.8918968133535661],"f1_score_macro":[0.5228247091510357],"AUC_weighted":[0.9267816862195225],"matthews_correlation":[0.18213474727779286],"average_precision_score_micro":[0.974195688767941]},"8343fe27-af60-4491-8dad-49e57370ae41_30":{"f1_score_weighted":[0.8657058753355867],"accuracy":[0.8996661608497725],"recall_score_weighted":[0.8996661608497725],"f1_score_micro":[0.8996661608497725],"average_precision_score_macro":[0.8059629132335779],"matthews_correlation":[0.3054950709004917],"precision_score_macro":[0.8659729766848174],"weighted_accuracy":[0.9830516808086017],"average_precision_score_micro":[0.9755095485471912],"AUC_macro":[0.9338623970178274],"recall_score_macro":[0.5639114002656495],"AUC_weighted":[0.9338623970178273],"precision_score_weighted":[0.8930710823293557],"log_loss":[0.22526267240859088],"norm_macro_recall":[0.1278228005312989],"AUC_micro":[0.9747655181783224],"average_precision_score_weighted":[0.9493889181966564],"precision_score_micro":[0.8996661608497725],"balanced_accuracy":[0.5639114002656495],"f1_score_macro":[0.5863624200295328],"recall_score_micro":[0.8996661608497725]},"8343fe27-af60-4491-8dad-49e57370ae41_5":{"recall_score_macro":[0.5854424894724115],"average_precision_score_micro":[0.9699017547771328],"average_precision_score_macro":[0.7495789216884937],"f1_score_weighted":[0.8723574493506927],"recall_score_micro":[0.899939301972686],"f1_score_micro":[0.8999393019726858],"f1_score_macro":[0.6167056034599755],"accuracy":[0.899939301972686],"AUC_weighted":[0.9036358037192604],"log_loss":[0.2389452090151209],"precision_score_macro":[0.8098557533920614],"AUC_micro":[0.9686734856003371],"matthews_correlation":[0.32502386526061355],"average_precision_score_weighted":[0.9337244181734766],"precision_score_micro":[0.899939301972686],"weighted_accuracy":[0.9780614775493157],"norm_macro_recall":[0.17088497894482288],"precision_score_weighted":[0.884051567498948],"balanced_accuracy":[0.5854424894724115],"AUC_macro":[0.9036358037192604],"recall_score_weighted":[0.899939301972686]},"8343fe27-af60-4491-8dad-49e57370ae41_4":{"AUC_macro":[0.925646054111389],"weighted_accuracy":[0.9681549756261891],"precision_score_macro":[0.7951088062107223],"norm_macro_recall":[0.3245144538597239],"f1_score_weighted":[0.8939502924262321],"recall_score_weighted":[0.9072837632776934],"recall_score_macro":[0.662257226929862],"precision_score_weighted":[0.893793005505491],"accuracy":[0.9072837632776934],"average_precision_score_weighted":[0.9432946732723817],"matthews_correlation":[0.437104212125669],"f1_score_macro":[0.7022036781816178],"precision_score_micro":[0.9072837632776934],"AUC_micro":[0.9734316675148118],"log_loss":[0.31389404101532276],"balanced_accuracy":[0.662257226929862],"recall_score_micro":[0.9072837632776934],"AUC_weighted":[0.9256460541113889],"f1_score_micro":[0.9072837632776934],"average_precision_score_macro":[0.7869329752898478],"average_precision_score_micro":[0.9721960248592625]},"8343fe27-af60-4491-8dad-49e57370ae41_33":{"AUC_micro":[0.9791411551506973],"AUC_macro":[0.9423653708932276],"balanced_accuracy":[0.7121708447468105],"average_precision_score_micro":[0.9799411940544493],"recall_score_macro":[0.7121708447468105],"accuracy":[0.9120182094081943],"log_loss":[0.18596563156714907],"matthews_correlation":[0.499905559123229],"recall_score_micro":[0.9120182094081943],"norm_macro_recall":[0.42434168949362083],"average_precision_score_weighted":[0.9528206459834057],"f1_score_macro":[0.7437865809922893],"f1_score_micro":[0.9120182094081943],"weighted_accuracy":[0.9616722777458673],"f1_score_weighted":[0.9048684953878819],"average_precision_score_macro":[0.8158666828570817],"precision_score_macro":[0.7948556413398105],"precision_score_micro":[0.9120182094081943],"recall_score_weighted":[0.9120182094081943],"precision_score_weighted":[0.9026329861477012],"AUC_weighted":[0.9423653708932276]},"8343fe27-af60-4491-8dad-49e57370ae41_12":{"AUC_weighted":[0.9236839344814683],"log_loss":[0.2518835303356076],"f1_score_micro":[0.9030652503793627],"precision_score_weighted":[0.8873500407010996],"f1_score_weighted":[0.88151249212797],"f1_score_macro":[0.6528672814981655],"AUC_macro":[0.9236839344814683],"recall_score_micro":[0.9030652503793627],"precision_score_macro":[0.8033609416496426],"average_precision_score_micro":[0.9733057650518437],"accuracy":[0.9030652503793627],"precision_score_micro":[0.9030652503793627],"average_precision_score_weighted":[0.9424276409866232],"AUC_micro":[0.9731850115478228],"norm_macro_recall":[0.2283089079147942],"balanced_accuracy":[0.6141544539573971],"recall_score_macro":[0.6141544539573971],"weighted_accuracy":[0.9748514945608446],"recall_score_weighted":[0.9030652503793627],"average_precision_score_macro":[0.7809958178668636],"matthews_correlation":[0.371808955756483]},"8343fe27-af60-4491-8dad-49e57370ae41_26":{"AUC_weighted":[0.9402946012602748],"weighted_accuracy":[0.958501242985753],"balanced_accuracy":[0.7334140197614252],"recall_score_micro":[0.9137177541729893],"recall_score_macro":[0.7334140197614252],"accuracy":[0.9137177541729893],"average_precision_score_micro":[0.9791691372752561],"f1_score_macro":[0.7587292938017134],"average_precision_score_weighted":[0.9518033429659001],"AUC_micro":[0.9788762206958166],"norm_macro_recall":[0.46682803952285024],"average_precision_score_macro":[0.8142986289084387],"precision_score_micro":[0.9137177541729893],"matthews_correlation":[0.5238653512977416],"precision_score_macro":[0.7940450216309015],"f1_score_micro":[0.9137177541729893],"f1_score_weighted":[0.9087742470644116],"recall_score_weighted":[0.9137177541729893],"precision_score_weighted":[0.9063742263480554],"log_loss":[0.31909581068420934],"AUC_macro":[0.9402946012602748]},"8343fe27-af60-4491-8dad-49e57370ae41_1":{"f1_score_weighted":[0.9099509978306767],"AUC_micro":[0.9806226429431634],"log_loss":[0.17675731767141806],"f1_score_macro":[0.7612094903843643],"average_precision_score_micro":[0.9814521425703413],"AUC_macro":[0.9470482354216786],"matthews_correlation":[0.5295913756255151],"precision_score_macro":[0.7993789575608424],"precision_score_weighted":[0.9076691237014514],"f1_score_micro":[0.9150834597875569],"precision_score_micro":[0.9150834597875569],"recall_score_micro":[0.9150834597875569],"recall_score_weighted":[0.9150834597875569],"AUC_weighted":[0.9470482354216786],"accuracy":[0.9150834597875569],"average_precision_score_weighted":[0.9559722737351815],"average_precision_score_macro":[0.8272281883688631],"recall_score_macro":[0.7342727234999709],"norm_macro_recall":[0.46854544699994183],"weighted_accuracy":[0.9599876665909527],"balanced_accuracy":[0.7342727234999709]},"8343fe27-af60-4491-8dad-49e57370ae41_0":{"accuracy":[0.9153262518968133],"average_precision_score_weighted":[0.95612678389923],"precision_score_micro":[0.9153262518968133],"matthews_correlation":[0.5463876676498807],"average_precision_score_macro":[0.8268817690624332],"weighted_accuracy":[0.955492910025417],"average_precision_score_micro":[0.9819407711877979],"f1_score_micro":[0.9153262518968133],"AUC_macro":[0.9491585177037773],"recall_score_macro":[0.7536446104870343],"recall_score_micro":[0.9153262518968133],"log_loss":[0.17223933574396963],"f1_score_macro":[0.7717552287143188],"balanced_accuracy":[0.7536446104870343],"recall_score_weighted":[0.9153262518968133],"norm_macro_recall":[0.5072892209740687],"precision_score_macro":[0.794327695398049],"AUC_micro":[0.9811398610577022],"AUC_weighted":[0.9491585177037773],"f1_score_weighted":[0.9122150096787482],"precision_score_weighted":[0.9102492525011827]},"8343fe27-af60-4491-8dad-49e57370ae41_7":{"recall_score_weighted":[0.9073748103186645],"norm_macro_recall":[0.37586848636657694],"AUC_weighted":[0.931981279341209],"log_loss":[0.21715996114351407],"precision_score_macro":[0.785452812591462],"f1_score_micro":[0.9073748103186645],"precision_score_weighted":[0.8963373607604541],"matthews_correlation":[0.4606988157883847],"accuracy":[0.9073748103186645],"average_precision_score_macro":[0.7840635548703856],"recall_score_macro":[0.6879342431832886],"recall_score_micro":[0.9073748103186645],"f1_score_macro":[0.7200908949171076],"precision_score_micro":[0.9073748103186645],"AUC_macro":[0.931981279341209],"AUC_micro":[0.9734438854105983],"weighted_accuracy":[0.9619039950527665],"balanced_accuracy":[0.6879342431832886],"f1_score_weighted":[0.8976980079890456],"average_precision_score_micro":[0.9700918743806852],"average_precision_score_weighted":[0.9445646754229331]},"8343fe27-af60-4491-8dad-49e57370ae41_11":{"f1_score_weighted":[0.88058093048496],"matthews_correlation":[0.5504520899457341],"AUC_macro":[0.9325353874117264],"recall_score_micro":[0.8632473444613049],"f1_score_micro":[0.8632473444613049],"precision_score_micro":[0.8632473444613049],"log_loss":[0.8153141772390111],"recall_score_weighted":[0.8632473444613049],"accuracy":[0.8632473444613049],"AUC_weighted":[0.9325353874117264],"precision_score_macro":[0.7125484787244653],"norm_macro_recall":[0.7142600926195017],"average_precision_score_weighted":[0.9438519178695752],"average_precision_score_micro":[0.909153907471486],"weighted_accuracy":[0.8647833713741603],"balanced_accuracy":[0.8571300463097508],"AUC_micro":[0.923552294482144],"average_precision_score_macro":[0.7813717442053983],"f1_score_macro":[0.7506588139712134],"precision_score_weighted":[0.9190200377031168],"recall_score_macro":[0.8571300463097508]},"8343fe27-af60-4491-8dad-49e57370ae41_10":{"AUC_weighted":[0.8997389493750425],"recall_score_weighted":[0.8879514415781488],"accuracy":[0.8879514415781488],"average_precision_score_micro":[0.9683233655141879],"f1_score_micro":[0.8879514415781488],"recall_score_macro":[0.5],"AUC_micro":[0.9675073328098627],"precision_score_weighted":[0.7884610378994246],"f1_score_macro":[0.47032487347763857],"weighted_accuracy":[0.9843203159290127],"balanced_accuracy":[0.5],"precision_score_micro":[0.8879514415781488],"matthews_correlation":[0.0],"f1_score_weighted":[0.83525313620102],"recall_score_micro":[0.8879514415781488],"average_precision_score_weighted":[0.9304320604731391],"log_loss":[0.2574988610368111],"norm_macro_recall":[0.0],"precision_score_macro":[0.4439757207890744],"average_precision_score_macro":[0.7389108213968492],"AUC_macro":[0.8997389493750425]},"8343fe27-af60-4491-8dad-49e57370ae41_22":{"recall_score_weighted":[0.749135053110774],"f1_score_macro":[0.6129776164657637],"AUC_micro":[0.8330078912040821],"accuracy":[0.749135053110774],"f1_score_weighted":[0.7910515232295333],"average_precision_score_weighted":[0.9054622570836957],"recall_score_micro":[0.749135053110774],"AUC_macro":[0.8069446374128857],"norm_macro_recall":[0.4512883771339105],"precision_score_macro":[0.6082990227651349],"recall_score_macro":[0.7256441885669552],"average_precision_score_macro":[0.6992920955536682],"AUC_weighted":[0.8069446374128857],"precision_score_micro":[0.749135053110774],"f1_score_micro":[0.7491350531107739],"average_precision_score_micro":[0.8068488519631728],"matthews_correlation":[0.31259305286659506],"log_loss":[0.5599197209626958],"precision_score_weighted":[0.8746908050789358],"weighted_accuracy":[0.7549885503779852],"balanced_accuracy":[0.7256441885669552]},"8343fe27-af60-4491-8dad-49e57370ae41_28":{"f1_score_macro":[0.5379744193233309],"AUC_micro":[0.971745722239748],"precision_score_weighted":[0.8906481117603684],"norm_macro_recall":[0.07024554435298307],"average_precision_score_micro":[0.972831015033665],"accuracy":[0.894567526555387],"log_loss":[0.2366620069479536],"precision_score_macro":[0.87577474427061],"matthews_correlation":[0.22813549574782482],"average_precision_score_macro":[0.7780330947216264],"f1_score_weighted":[0.8529411779201753],"AUC_macro":[0.9201965317483227],"balanced_accuracy":[0.5351227721764915],"precision_score_micro":[0.894567526555387],"recall_score_weighted":[0.894567526555387],"recall_score_micro":[0.894567526555387],"weighted_accuracy":[0.9838371988596796],"f1_score_micro":[0.894567526555387],"AUC_weighted":[0.9201965317483227],"recall_score_macro":[0.5351227721764915],"average_precision_score_weighted":[0.9418182586449376]},"8343fe27-af60-4491-8dad-49e57370ae41_39":{"balanced_accuracy":[0.7425762231452316],"precision_score_weighted":[0.908999433104374],"recall_score_micro":[0.9154779969650987],"precision_score_micro":[0.9154779969650987],"log_loss":[0.1926774488917747],"f1_score_micro":[0.9154779969650987],"average_precision_score_macro":[0.8277627857824952],"recall_score_macro":[0.7425762231452316],"f1_score_macro":[0.7662153155369943],"AUC_micro":[0.9811555513596035],"AUC_macro":[0.9492075328058023],"norm_macro_recall":[0.48515244629046334],"recall_score_weighted":[0.9154779969650987],"matthews_correlation":[0.5378382881238783],"AUC_weighted":[0.9492075328058023],"average_precision_score_micro":[0.9819687694271151],"precision_score_macro":[0.7983033653754065],"f1_score_weighted":[0.9111630006796917],"accuracy":[0.9154779969650987],"average_precision_score_weighted":[0.9563340481490646],"weighted_accuracy":[0.9584254729565052]},"8343fe27-af60-4491-8dad-49e57370ae41_14":{"precision_score_weighted":[0.7884610378994246],"AUC_micro":[0.9615244277322746],"recall_score_macro":[0.5],"average_precision_score_macro":[0.6946912810130594],"AUC_weighted":[0.8697944541112408],"recall_score_weighted":[0.8879514415781488],"recall_score_micro":[0.8879514415781488],"f1_score_weighted":[0.83525313620102],"average_precision_score_weighted":[0.9165839209560372],"matthews_correlation":[0.0],"precision_score_micro":[0.8879514415781488],"balanced_accuracy":[0.5],"accuracy":[0.8879514415781488],"log_loss":[0.2634925249845744],"AUC_macro":[0.8697944541112408],"average_precision_score_micro":[0.9614061934373492],"norm_macro_recall":[0.0],"f1_score_micro":[0.8879514415781488],"f1_score_macro":[0.47032487347763857],"weighted_accuracy":[0.9843203159290127],"precision_score_macro":[0.4439757207890744]},"8343fe27-af60-4491-8dad-49e57370ae41_17":{"recall_score_weighted":[0.8995447647951442],"norm_macro_recall":[0.33884144059665244],"balanced_accuracy":[0.6694207202983262],"average_precision_score_weighted":[0.9371736930131268],"f1_score_macro":[0.6934831890437638],"f1_score_micro":[0.8995447647951442],"accuracy":[0.8995447647951442],"AUC_weighted":[0.9133389169102444],"precision_score_macro":[0.7575206151832397],"precision_score_weighted":[0.8871858594850741],"recall_score_micro":[0.8995447647951442],"weighted_accuracy":[0.9566956471503527],"f1_score_weighted":[0.888409138568956],"AUC_macro":[0.9133389169102444],"AUC_micro":[0.969669499701806],"matthews_correlation":[0.41139266982643274],"precision_score_micro":[0.8995447647951442],"average_precision_score_macro":[0.7605988101094721],"log_loss":[0.23268545635231072],"recall_score_macro":[0.6694207202983262],"average_precision_score_micro":[0.9689439167082583]},"8343fe27-af60-4491-8dad-49e57370ae41_31":{"f1_score_weighted":[0.9065104406142629],"average_precision_score_weighted":[0.9528332055956563],"precision_score_micro":[0.9130197268588771],"balanced_accuracy":[0.7189449721817834],"AUC_weighted":[0.9429583830860487],"recall_score_macro":[0.7189449721817834],"AUC_micro":[0.9793437797186615],"log_loss":[0.182937872815521],"recall_score_micro":[0.9130197268588771],"recall_score_weighted":[0.9130197268588771],"precision_score_weighted":[0.9042132298962006],"average_precision_score_macro":[0.8154050878684476],"accuracy":[0.9130197268588771],"f1_score_micro":[0.9130197268588771],"precision_score_macro":[0.7964507922641129],"matthews_correlation":[0.5093191526534719],"weighted_accuracy":[0.9612258972875203],"f1_score_macro":[0.7493640662744622],"average_precision_score_micro":[0.9801957662213374],"norm_macro_recall":[0.4378899443635671],"AUC_macro":[0.9429583830860485]},"8343fe27-af60-4491-8dad-49e57370ae41_38":{"accuracy":[0.9153262518968134],"f1_score_micro":[0.9153262518968134],"AUC_micro":[0.9812824415528196],"balanced_accuracy":[0.731848347231969],"average_precision_score_micro":[0.9821001188974268],"matthews_correlation":[0.5285201415769926],"recall_score_macro":[0.731848347231969],"f1_score_weighted":[0.9098497697166034],"precision_score_macro":[0.8013406494837817],"AUC_weighted":[0.9499629521686856],"precision_score_micro":[0.9153262518968134],"average_precision_score_weighted":[0.9566142795404632],"log_loss":[0.17498569908674497],"AUC_macro":[0.9499629521686856],"recall_score_micro":[0.9153262518968134],"recall_score_weighted":[0.9153262518968134],"average_precision_score_macro":[0.8286025184347097],"norm_macro_recall":[0.4636966944639383],"weighted_accuracy":[0.9609031981004833],"f1_score_macro":[0.7601631251001868],"precision_score_weighted":[0.9076364146208966]},"8343fe27-af60-4491-8dad-49e57370ae41_32":{"AUC_weighted":[0.9450057650519907],"f1_score_macro":[0.7692375139021397],"f1_score_micro":[0.9136267071320182],"precision_score_macro":[0.788183048875329],"average_precision_score_weighted":[0.9534638797372832],"AUC_macro":[0.9450057650519905],"log_loss":[0.17933626553878054],"weighted_accuracy":[0.9534021999605298],"recall_score_weighted":[0.9136267071320182],"precision_score_weighted":[0.9089433217085521],"norm_macro_recall":[0.5070213632843444],"AUC_micro":[0.9800018375199466],"matthews_correlation":[0.5405618342145526],"accuracy":[0.9136267071320182],"balanced_accuracy":[0.7535106816421722],"recall_score_micro":[0.9136267071320182],"f1_score_weighted":[0.9108701286564065],"average_precision_score_micro":[0.9807332204705185],"average_precision_score_macro":[0.8175098313041292],"recall_score_macro":[0.7535106816421722],"precision_score_micro":[0.9136267071320182]},"8343fe27-af60-4491-8dad-49e57370ae41_8":{"f1_score_weighted":[0.8437052738366463],"precision_score_macro":[0.685024557538448],"recall_score_micro":[0.8910166919575115],"norm_macro_recall":[0.03435371648135392],"log_loss":[0.25548070809918155],"AUC_macro":[0.8999142507802699],"recall_score_macro":[0.5171597963058536],"f1_score_macro":[0.502615561655768],"precision_score_micro":[0.8910166919575115],"recall_score_weighted":[0.8910166919575115],"weighted_accuracy":[0.9838442635701783],"precision_score_weighted":[0.8451126420891626],"AUC_weighted":[0.8999142507802699],"AUC_micro":[0.9676119563139995],"average_precision_score_weighted":[0.9331601613704363],"average_precision_score_micro":[0.9685371039182499],"f1_score_micro":[0.8910166919575115],"balanced_accuracy":[0.5171597963058536],"matthews_correlation":[0.10863959896608304],"average_precision_score_macro":[0.750917460739744],"accuracy":[0.8910166919575115]},"8343fe27-af60-4491-8dad-49e57370ae41_9":{"AUC_weighted":[0.922615064635622],"precision_score_macro":[0.779340700722136],"f1_score_micro":[0.9033687405159332],"log_loss":[0.2398196340372846],"average_precision_score_macro":[0.7847492194438285],"recall_score_micro":[0.9033687405159332],"precision_score_weighted":[0.8876056141964608],"precision_score_micro":[0.9033687405159332],"average_precision_score_weighted":[0.942741880546661],"f1_score_macro":[0.6847279568637529],"accuracy":[0.9033687405159332],"average_precision_score_micro":[0.966442641186861],"balanced_accuracy":[0.6466835588866304],"AUC_micro":[0.9704994876589123],"recall_score_weighted":[0.9033687405159332],"norm_macro_recall":[0.29336711777326097],"weighted_accuracy":[0.9671626857091186],"matthews_correlation":[0.40450957017901956],"recall_score_macro":[0.6466835588866304],"AUC_macro":[0.922615064635622],"f1_score_weighted":[0.888418074282661]},"8343fe27-af60-4491-8dad-49e57370ae41_6":{"AUC_weighted":[0.9057641164093356],"log_loss":[0.23635966731121355],"f1_score_macro":[0.6242575282375705],"balanced_accuracy":[0.5917918768086842],"precision_score_micro":[0.8992716236722307],"recall_score_weighted":[0.8992716236722307],"matthews_correlation":[0.3271255457457182],"AUC_macro":[0.9057641164093356],"precision_score_macro":[0.7923476908341728],"average_precision_score_micro":[0.9698375587047445],"recall_score_micro":[0.8992716236722307],"weighted_accuracy":[0.97564601523124],"f1_score_weighted":[0.8736814591055589],"f1_score_micro":[0.8992716236722307],"norm_macro_recall":[0.1835837536173684],"AUC_micro":[0.9690804709393227],"average_precision_score_weighted":[0.9318910099740316],"average_precision_score_macro":[0.7411070393963273],"precision_score_weighted":[0.8811941449190931],"accuracy":[0.8992716236722307],"recall_score_macro":[0.5917918768086842]},"8343fe27-af60-4491-8dad-49e57370ae41_19":{"precision_score_macro":[0.4439757207890744],"AUC_weighted":[0.8717172044276656],"average_precision_score_macro":[0.6996096768811019],"norm_macro_recall":[0.0],"log_loss":[0.2746575337834078],"f1_score_micro":[0.8879514415781488],"average_precision_score_micro":[0.9629354433843392],"weighted_accuracy":[0.9843203159290127],"recall_score_weighted":[0.8879514415781488],"matthews_correlation":[0.0],"recall_score_macro":[0.5],"accuracy":[0.8879514415781488],"f1_score_macro":[0.47032487347763857],"AUC_macro":[0.8717172044276656],"precision_score_micro":[0.8879514415781488],"recall_score_micro":[0.8879514415781488],"average_precision_score_weighted":[0.9184223913235845],"balanced_accuracy":[0.5],"AUC_micro":[0.9619291979156352],"precision_score_weighted":[0.7884610378994246],"f1_score_weighted":[0.83525313620102]},"8343fe27-af60-4491-8dad-49e57370ae41_13":{"AUC_weighted":[0.8290323785115394],"f1_score_macro":[0.6329242287823641],"matthews_correlation":[0.34647420374814203],"average_precision_score_macro":[0.6893031015472231],"AUC_micro":[0.8394209555564254],"recall_score_micro":[0.767647951441578],"weighted_accuracy":[0.7731018820441001],"recall_score_weighted":[0.767647951441578],"f1_score_micro":[0.767647951441578],"average_precision_score_weighted":[0.9077855330193743],"log_loss":[0.5913372729575987],"average_precision_score_micro":[0.8063857780756761],"accuracy":[0.767647951441578],"AUC_macro":[0.8290323785115394],"balanced_accuracy":[0.7457279977160406],"norm_macro_recall":[0.49145599543208085],"precision_score_micro":[0.767647951441578],"f1_score_weighted":[0.8053705707412281],"precision_score_weighted":[0.8812421453131357],"precision_score_macro":[0.6222563551409191],"recall_score_macro":[0.7457279977160406]},"8343fe27-af60-4491-8dad-49e57370ae41_29":{"AUC_micro":[0.9807173419974624],"precision_score_micro":[0.9137784522003034],"matthews_correlation":[0.5276731660965839],"f1_score_macro":[0.7611882685732771],"f1_score_weighted":[0.9093152422683854],"recall_score_weighted":[0.9137784522003034],"average_precision_score_macro":[0.8240692554673708],"recall_score_micro":[0.9137784522003034],"weighted_accuracy":[0.9575122919710177],"f1_score_micro":[0.9137784522003034],"balanced_accuracy":[0.7376724594655213],"AUC_macro":[0.9476929068854764],"AUC_weighted":[0.9476929068854764],"precision_score_macro":[0.7929531035630804],"accuracy":[0.9137784522003034],"log_loss":[0.17543280668687453],"average_precision_score_micro":[0.9814235483801239],"norm_macro_recall":[0.4753449189310426],"precision_score_weighted":[0.9069554333456221],"recall_score_macro":[0.7376724594655213],"average_precision_score_weighted":[0.9552296947497659]},"8343fe27-af60-4491-8dad-49e57370ae41_23":{"log_loss":[0.25877002104564995],"f1_score_macro":[0.6158707660124658],"average_precision_score_weighted":[0.9268407371430591],"accuracy":[0.8993323216995448],"precision_score_weighted":[0.8822289537345505],"f1_score_micro":[0.8993323216995448],"AUC_weighted":[0.8765452788499491],"average_precision_score_macro":[0.735624343226064],"AUC_macro":[0.8765452788499491],"recall_score_macro":[0.5850517166606923],"recall_score_weighted":[0.8993323216995448],"average_precision_score_micro":[0.9641215690896004],"precision_score_micro":[0.8993323216995448],"weighted_accuracy":[0.9773881624919151],"norm_macro_recall":[0.17010343332138472],"matthews_correlation":[0.32028583465573945],"precision_score_macro":[0.8021482858972547],"balanced_accuracy":[0.5850517166606923],"AUC_micro":[0.9633153741471535],"recall_score_micro":[0.8993323216995448],"f1_score_weighted":[0.8719123806622491]},"8343fe27-af60-4491-8dad-49e57370ae41_24":{"balanced_accuracy":[0.5775058413494202],"average_precision_score_weighted":[0.917862484702803],"log_loss":[0.2791197647655823],"precision_score_micro":[0.8939908952959028],"AUC_macro":[0.860024417208229],"precision_score_weighted":[0.8692738362722032],"average_precision_score_micro":[0.9536397299829857],"recall_score_micro":[0.8939908952959028],"f1_score_macro":[0.6033405182413158],"accuracy":[0.8939908952959028],"norm_macro_recall":[0.1550116826988403],"AUC_weighted":[0.8600244172082292],"weighted_accuracy":[0.9726139045334687],"f1_score_micro":[0.8939908952959028],"average_precision_score_macro":[0.7054631139682155],"AUC_micro":[0.9578195269882863],"f1_score_weighted":[0.8667897258404237],"precision_score_macro":[0.749304586163283],"recall_score_macro":[0.5775058413494202],"matthews_correlation":[0.27791412055523773],"recall_score_weighted":[0.8939908952959028]},"8343fe27-af60-4491-8dad-49e57370ae41_2":{"weighted_accuracy":[0.9803824443691873],"log_loss":[0.23514059189176253],"AUC_macro":[0.9103600484965145],"precision_score_weighted":[0.8814763440179474],"average_precision_score_micro":[0.9702354107656099],"recall_score_micro":[0.8967830045523522],"average_precision_score_macro":[0.7546458390822712],"f1_score_micro":[0.8967830045523522],"AUC_micro":[0.9698583543834521],"AUC_weighted":[0.9103600484965145],"recall_score_macro":[0.5602653199607495],"norm_macro_recall":[0.12053063992149893],"f1_score_weighted":[0.8624818644150759],"matthews_correlation":[0.2676246552395144],"average_precision_score_weighted":[0.9347626112134589],"precision_score_macro":[0.8163732638986503],"accuracy":[0.8967830045523522],"recall_score_weighted":[0.8967830045523522],"balanced_accuracy":[0.5602653199607495],"precision_score_micro":[0.8967830045523522],"f1_score_macro":[0.5776254240527396]}}